<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="This paper uncovers the potential of model editing to trigger LLMs collapse and proposes using perplexity as a surrogate metric to monitor model alterations.">
  <meta property="og:title" content="The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse"/>
  <meta property="og:description" content="This paper uncovers the potential of model editing to trigger LLMs collapse and proposes using perplexity as a surrogate metric to monitor model alterations."/>
  <meta property="og:url" content="https://yangwl.site/collapse-in-model-editing"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/intro.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse">
  <meta name="twitter:description" content="This paper uncovers the potential of model editing to trigger LLMs collapse and proposes using perplexity as a surrogate metric to monitor model alterations.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/intro.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Model editing, knowledge editing, large language models">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse</title>
  <link rel="icon" type="image/x-icon" href="static/images/butterfly.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">The Mirage of Model Editing: </br>Revisiting Evaluation in the <span style="font-variant: small-caps;">Wild</span></h1>
            <p style="color: red; font-style: italic; font-weight: bold; font-size: 1.6rem; margin-top: -10px; margin-bottom: 15px;">
              Are We Really Making Much Progress?
            </p>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yangwl.site" target="_blank">Wanli Yang</a><sup>1,2</sup>,</span>
                <a href="http://ofey.me" target="_blank">Fei Sun</a><sup>†1</sup>,</span>
                <a href="https://sumsky21.github.io" target="_blank">Jiajun Tan</a><sup>1,2</sup>,</span>
                <a href="https://albert-ma.github.io" target="_blank">Xinyu Ma</a><sup>3</sup>,</span>
                <a href="https://caoqi92.github.io" target="_blank">Qi Cao</a><sup>1</sup>,</span>
                <a href="https://www.yindawei.com" target="_blank">Dawei Yin</a><sup>3</sup>,</span>
                <a href="https://dblp.org/pid/98/917.html" target="_blank">Huawei Shen</a><sup>1,2</sup>,</span>
                <a href="https://scholar.google.com/citations?user=hY8aLqAAAAAJ&hl" target="_blank">Xueqi Cheng</a><sup>1,2</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>State Key Laboratory of AI Safety, Institute of Computing Technology, CAS<br> <sup>2</sup>University of Chinese Academy of Sciences &nbsp;&nbsp;&nbsp; <sup>3</sup>Baidu Inc.
              </span>
              <span class="cor-auth"><small><br><sup>†</sup>Corresponding Author</small></span>
            </div>
                  <!-- Supplementary PDF link 
                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2502.11177" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                    -->

                    <!-- Supplementary PDF link 
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2502.11177" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>ArXiv</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/WanliYoung/Revisit-Editing-Evaluation" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                  </span>

                  <!-- Google Drive link -->
                  <span class="link-block">
                    <a href="https://drive.google.com/drive/folders/1w9r7CL_a9k3HiorfSvE-RiShHvvrshoy?usp=sharing" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>Data</span>
                    </a>
                  </span>
            </div>
          </div>

          <div style="text-align: center;">
            <a name="intro">
              <img src="static/images/fig_intro.png" alt="intro" style="width: 580pt;" />
            </a>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        Your video here
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
End teaser video -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Despite near-perfect results reported in the literature, the effectiveness of model editing in real-world applications remains unclear. To bridge this gap, we introduce QAEdit, a new benchmark aligned with widely used question answering (QA) datasets, and <span style="font-variant: small-caps;">Wild</span>, a task-agnostic evaluation framework designed to better reflect real-world usage of model editing. Our single editing experiments show that current editing methods perform substantially worse than previously reported (38.5% vs. 96.8%). We demonstrate that it stems from issues in the synthetic evaluation practices of prior work. Among them, the most severe is the use of teacher forcing during testing, which leaks both content and length of ground truth, leading to overestimated performance. Furthermore, we simulate practical deployment by sequential editing, revealing that current approaches fail drastically with only 1000 edits. This work calls for a shift in editing research toward rigorous evaluation and the development of robust, scalable methods that can reliably update knowledge in LLMs for real-world use.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Satisfactory Advances of Model Editing</h2>
          <div class="Text" style="text-align: left; font-size: medium;">
            <div class="item">
              <a name="Fig1">
                <img src="static/images/exist_results.png" alt="Existing results of model editing." style="margin: 0 0;" width="100%" height="60%"/>
              </a>
              <h2 class="subtitle has-text-centered" style="font-size: medium;">
                Table 1: Evaluation results of mainstream model editing techniques on benchmark datasets, as reported in "A Comprehensive Study of Knowledge Editing for Large Language Models".
              </h2>
            </div>
            <br>
            <p style="text-align: justify;">
            Recent works report near-perfect results of model editing techniques on corresponding benchmarks, suggesting substantial progress toward efficient and effective update of LLMs. However, these results often come from synthetic, oversimplified evaluation settings (e.g., identical prompts for editing and testing) that may fail to capture real-world complexities. This disparity raises a critical question: <span style="font-style: italic; font-weight: bold; color: red;">Can these promising results in the literature translate to practical applications?</span>
            </p>
          </div>
        </div>
      </div>
    </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Evaluate Editing in the Wild</h2>
          <div class="Text" style="text-align: left; font-size: medium;">
            <div class="item">
              <a name="Fig2">
                <img src="static/images/QAEdit_pipe.png" alt="Correlations between Perplexity and Performance" style="margin: 0 15%;" width="70%" height="60%"/>
              </a>
              <h2 class="subtitle has-text-centered" style="font-size: medium;">
                Figure 1: Illustration of QAEdit pipeline to evaluate model editing in real-world QA.
              </h2>
            </div>
            <br>
            <p style="text-align: justify;">
            To rigorously examine the practical utility of model editing, we <span style="font-weight: bold;">focus on the most fundamental and widely studied task of QA</span> for two reasons: i) They offer clear evaluation criteria and broad applicability; ii) If current editing methods struggle on basic QA tasks, then they are unlikely to succeed in more challenging scenarios. Specifically, we apply editing methods to correct LLMs' errors in QA tasks and assess the improvement by re-evaluating edited LLMs on a standard QA evaluation framework (lm-evaluation-harness), as illustrated in Figure 1.
            </p>
            <a name="Fig2">
              <img src="static/images/preliminary_results.png" alt="Correlations between Perplexity and Performance" style="margin: 2% 10%;" width="80%" height="60%"/>
            </a>
            <h2 class="subtitle has-text-centered" style="font-size: medium;">
              Table 2: Accuracy of edited Llama-2-7b-chat on questions it failed before editing in QAEdit.
            </h2>
          </div>
        </div>
      </div>
    </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Model Collapse Induced by Editing</h2>
          <h3 class="title is-4" style="text-align: center;">Single Editing</h3>
          <div class="Text" style="text-align: left; font-size: medium;">
            <div class="item">
              <a name="Fig3">
                <img src="static/images/case.png" alt="Edit Cases Trigger Collapse" style="margin: 0 25%;" width="50%" height="20%"/>
              </a>
              <h2 class="subtitle has-text-centered" style="font-size: medium;">
                Table 1: Examples of HardCF that induce collapse in corresponding LLMs through a single ROME edit, with the "Normal" row showcasing other normal cases from COUNTERFACT for contrast.
              </h2>
            </div>
            <br>
            Upon examining the perplexity, we find that ROME consistently causes all three LLMs under study (GPT-2-XL, GPT-J, and Llama2-7b) to collapse with a <b>single edit</b> when applied to COUNTERFACT. Examples presented in Table 1 indicate that, for GPT-2-XL and GPT-J, the samples causing model collapse primarily featuring subjects that are single, commonly used words; for Llama2-7b, the subjects in these challenging cases usually encompass names of individuals or entities, presented in a particular format. 
            <br>
            <div class="item">
              <a name="Fig4">
                <img src="static/images/param.png" alt="Parameters Variation" style="margin: 0 10%;" width="80%" height="60%"/>
              </a>
              <h2 class="subtitle has-text-centered" style="font-size: medium;">
                Figure 3: The absolute difference between the weights of the edited layer (Layers.5.mlp.down_proj) and its original weights for ROME-edited Llama2-7b models.
              </h2>
            </div>
            <br>
            To uncover the root causes of model collapse, we initiated a preliminary investigation into the parameter changes in edited models. Figure 3 shows that the collapsed model experienced significantly larger parameter changes than the stable edited model.
          </div>
          <br>
          <h3 class="title is-4" style="text-align: center;">Sequential Editing</h3>
          <div class="Text" style="text-align: left; font-size: medium;">
            <div class="item">
              <a name="Fig5">
                <img src="static/images/seq.png" alt="Sequential Editing Collapse" style="margin: 0 5%;" width="90%" height="20%"/>
              </a>
              <h2 class="subtitle has-text-centered" style="font-size: medium;">
                Figure 4: Perplexity evolution over 107 editing iterations for normal and hard cases. The y-axes are tailored for each subplot accordingly due to the the significant variation in the magnitude of perplexity changes.
              </h2>
            </div>
            <br>
            Further experiments in sequential editing reveal that, hard cases from single editing can induce model collapse under nearly all the combinations examined. Conversely, normal cases that are randomly sampled from the rest of COUNTERFACT, do not compromise the integrity of models when edited by ROME and MEMIT.
          </div>
        </div>
      </div>
    </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">HardEdit: A Challenging Dataset</h2>
          <div class="Text" style="text-align: left; font-size: medium;">
            <div class="item">
              <a name="Fig6">
                <img src="static/images/dataval.png" alt="Valdation for HardEdit" style="margin: 0 5%;" width="90%" height="60%"/>
              </a>
              <h2 class="subtitle has-text-centered" style="font-size: medium;">
                Figure 5: Perplexity in three LLMs, each edited by four different methods sequentially on the HardEdit dataset.
              </h2>
            </div>
            <br>
            To further facilitate comprehensive evaluations of future advanced methods, we crafted a challenging dataset, termed HardEdit, based on the patterns derived from the hard cases. Extensive experiments confirm the efficacy of the dataset in identifying the potential risks of editing algorithms.
        </div>
      </div>
    </div>
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{yang-etal-2024-butterfly,
    title = "The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse",
    author = "Yang, Wanli  and
      Sun, Fei  and
      Ma, Xinyu  and
      Liu, Xun  and
      Yin, Dawei  and
      Cheng, Xueqi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.322",
    pages = "5419--5437",
    abstract = "Although model editing has shown promise in revising knowledge in Large Language Models (LLMs), its impact on the inherent capabilities of LLMs is often overlooked. In this work, we reveal a critical phenomenon: even a single edit can trigger model collapse, manifesting as significant performance degradation in various benchmark tasks. However, benchmarking LLMs after each edit, while necessary to prevent such collapses, is impractically time-consuming and resource-intensive. To mitigate this, we propose using perplexity as a surrogate metric, validated by extensive experiments demonstrating changes in an edited model{'}s perplexity are strongly correlated with its downstream task performances. We further conduct an in-depth study on sequential editing, a practical setting for real-world scenarios, across various editing methods and LLMs, focusing on hard cases from our previous single edit studies. The results indicate that nearly all examined editing methods result in model collapse after only few edits. To facilitate further research, we have utilized GPT-3.5 to develop a new dataset, HardEdit, based on those hard cases. This dataset aims to establish the foundation for pioneering research in reliable model editing and the mechanisms underlying editing-induced model collapse. We hope this work can draw the community{'}s attention to the potential risks inherent in model editing practices.",
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
