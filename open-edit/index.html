<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="icon" type="image/png" href="static/images/cup.png">
  <title>OpenEdit: A Leaderboard of Model Editing</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 2rem;
      line-height: 1.6;
    }
    h1, h2, h3 {
      color: #2c3e50;
    }
    .description {
      background-color: #f7f7f7;
      padding: 1rem;
      border-left: 4px solid #3498db;
      margin-bottom: 2rem;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 2rem;
      font-family: Arial, sans-serif;
    }
    th, td {
      border: 1px solid #ccc;
      padding: 0.6rem;
      text-align: center;
    }
    th {
      background-color: #f5f5f5;
    }
    .model-header {
      background-color: #ffffff;
      font-weight: bold;
      text-align: left;
      padding: 0.8rem;
      font-size: 1.1rem;
    }
    .dataset-section {
      margin-bottom: 3rem;
    }
  </style>
</head>
<body>
  <!-- <h1>ðŸ“Š OpenEdit Leaderboard</h1> -->
  <h1 class="title is-5" style="margin-bottom: 0.5rem;">
    <img src="static/images/cup.png" alt="Leaderboard Icon" style="width: 1.1em; height: 1.3em; vertical-align: middle; margin-right: 0.1em;">
    OpenEdit Leaderboard
  </h1>

  <div class="description">
    <p>
      This leaderboard presents a unified evaluation of recent <strong>model editing techniques</strong> across multiple LLMs and datasets.
      The experiments were conducted under consistent settings to ensure comparability.
    </p>
    <p><strong>Large Language Models:</strong> LLaMA-3-8B-Instruct, Qwen2.5-7B-Instruct, Mistral-7B-v0.1<br>
       <strong>Editing methods:</strong> MEMIT, WISE, AlphaEdit, RLEdit<br>
       <strong>Datasets:</strong> ZsRE, <span style="font-variant: small-caps;">CounterFact</span><br>
       <strong>Metrics:</strong> Reliability, Generalization, Capability (average performance of edited models on GSM8K, MMLU, Natural Questions, WMT, and SST2)</p>
  </div>

  <div class="dataset-section">
    <h2>ZsRE Leaderboard</h2>

    <table>
      <thead>
        <tr>
          <th>Method</th>
          <th>Reliability</th>
          <th>Generalization</th>
          <th>Capability</th>
        </tr>
      </thead>
    
      <tbody>
        <!-- LLaMA3-8B section -->
        <tr>
          <td colspan="4" class="model-header" style="text-align: center;">LLaMA-3-8B-Instruct</td>
        </tr>
        <td style="font-weight: bold;">Pre-Edit</td>
        <td>0.03%</td>
        <td>0.10%</td>
        <td>57.26%</td>
        <tr>
          <td>MEMIT</td>
          <td>26.23%</td>
          <td>23.30%</td>
          <td>25.67%</td>
        </tr>
        <tr>
          <td>WISE</td>
          <td>4.17%</td>
          <td>3.50%</td>
          <td>-</td>
        </tr>
        <tr>
          <td>AlphaEdit</td>
          <td>64.50%</td>
          <td>40.57%</td>
          <td>54.71%</td>
        </tr>
        <tr>
          <td>RLEdit</td>
          <td>66.67%</td>
          <td>59.40%</td>
          <td>57.41%</td>
        </tr>
    
        <!-- Qwen 2.5 section -->
        <tr>
          <td colspan="4" class="model-header" style="text-align: center;">Qwen2.5-7B-Instruct</td>
        </tr>
        <td style="font-weight: bold;">Pre-Edit</td>
        <td>0.00%</td>
        <td>0.00%</td>
        <td>58.52%</td>
        <tr>
          <td>MEMIT</td>
          <td>39.57%</td>
          <td>32.10%</td>
          <td>47.87%</td>
        </tr>
        <tr>
          <td>WISE</td>
          <td>7.67%</td>
          <td>5.23%</td>
          <td>-</td>
        </tr>
        <tr>
          <td>AlphaEdit</td>
          <td>2.70%</td>
          <td>2.33%</td>
          <td>16.31%</td>
        </tr>
        <tr>
          <td>RLEdit</td>
          <td>54.57%</td>
          <td>47.60%</td>
          <td>60.74%</td>
        </tr>

        <tr>
          <td colspan="4" class="model-header" style="text-align: center;">Mistral-7B-v0.1</td>
        </tr>
        <td style="font-weight: bold;">Pre-Edit</td>
        <td>0.00%</td>
        <td>0.00%</td>
        <td>44.82%</td>
        <tr>
          <td>MEMIT</td>
          <td>24.30%</td>
          <td>19.60%</td>
          <td>18.11%</td>
        </tr>
        <tr>
          <td>WISE</td>
          <td>15.87%</td>
          <td>11.33%</td>
          <td>-</td>
        </tr>
        <tr>
          <td>AlphaEdit</td>
          <td>3.30%</td>
          <td>3.00%</td>
          <td>15.13%</td>
        </tr>
        <tr>
          <td>RLEdit</td>
          <td>26.10%</td>
          <td>19.53%</td>
          <td>21.30%</td>
        </tr>
      </tbody>
    </table>

  </div>

  <div class="dataset-section">
    <h2>CounterFact Leaderboard</h2>
    <table>
      <thead>
        <tr>
          <th>Method</th>
          <th>Reliability</th>
          <th>Generalization</th>
          <th>Capability</th>
        </tr>
      </thead>
      <tbody>
        <!-- LLaMA3-8B section -->
        <tr>
          <td colspan="4" class="model-header" style="text-align: center;">LLaMA-3-8B-Instruct</td>
        </tr>
        <td style="font-weight: bold;">Pre-Edit</td>
        <td>0.00%</td>
        <td>0.13%</td>
        <td>57.26%</td>
        <tr>
          <td>MEMIT</td>
          <td>71.23%</td>
          <td>33.93%</td>
          <td>~%</td>
        </tr>
        <tr>
          <td>WISE</td>
          <td>16.47%</td>
          <td>4.53%</td>
          <td>-</td>
        </tr>
        <tr>
          <td>AlphaEdit</td>
          <td>93.03%</td>
          <td>28.13%</td>
          <td>~%</td>
        </tr>
        <tr>
          <td>RLEdit</td>
          <td>~%</td>
          <td>~%</td>
          <td>~%</td>
        </tr>
    
        <!-- Qwen 2.5 section -->
        <tr>
          <td colspan="4" class="model-header" style="text-align: center;">Qwen2.5-7B-Instruct</td>
        </tr>
        <td style="font-weight: bold;">Pre-Edit</td>
        <td>0.07%</td>
        <td>0.07%</td>
        <td>58.52%</td>
        <tr>
          <td>MEMIT</td>
          <td>68.87%</td>
          <td>19.23%</td>
          <td>~%</td>
        </tr>
        <tr>
          <td>WISE</td>
          <td>17.37%</td>
          <td>4.43%</td>
          <td>-</td>
        </tr>
        <tr>
          <td>AlphaEdit</td>
          <td>33.33%</td>
          <td>10.87%</td>
          <td>~%</td>
        </tr>
        <tr>
          <td>RLEdit</td>
          <td>~%</td>
          <td>~%</td>
          <td>~%</td>
        </tr>

        <tr>
          <td colspan="4" class="model-header" style="text-align: center;">Mistral-7B-v0.1</td>
        </tr>
        <td style="font-weight: bold;">Pre-Edit</td>
        <td>0.13%</td>
        <td>0.17%</td>
        <td>44.82%</td>
        <tr>
          <td>MEMIT</td>
          <td>35.20%</td>
          <td>17.27%</td>
          <td>~%</td>
        </tr>
        <tr>
          <td>WISE</td>
          <td>26.17%</td>
          <td>8.70%</td>
          <td>-</td>
        </tr>
        <tr>
          <td>AlphaEdit</td>
          <td>7.63%</td>
          <td>4.00%</td>
          <td>~%</td>
        </tr>
        <tr>
          <td>RLEdit</td>
          <td>~%</td>
          <td>~%</td>
          <td>~%</td>
        </tr>
      </tbody>
    </table>
  </div>
</body>
</html>